{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cube Detection Demo (Scenes + OpenCV)\n",
        "\n",
        "This notebook loads a scenario YAML from `generated_scenarios/`, renders a camera frame via Drake's `MakeHardwareStation`, and runs a simple OpenCV color-based cube detector (with depth sampling for range).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pydrake.all import ImageRgba8U\n",
        "from manipulation.station import LoadScenario, MakeHardwareStation\n",
        "\n",
        "# Paths\n",
        "ROOT = Path(__file__).resolve().parents[2] if '__file__' in globals() else Path.cwd().resolve()\n",
        "SCENARIO_DIR = ROOT / \"src\" / \"experiments_finalproject\" / \"generated_scenarios\"\n",
        "print(f\"Project root: {ROOT}\")\n",
        "print(f\"Scenario dir: {SCENARIO_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose a scenario YAML\n",
        "available = sorted(p.name for p in SCENARIO_DIR.glob(\"*.yaml\"))\n",
        "if not available:\n",
        "    raise FileNotFoundError(f\"No YAML files in {SCENARIO_DIR}\")\n",
        "scene_name = available[0]  # pick first by default; change to try others\n",
        "scene_path = SCENARIO_DIR / scene_name\n",
        "print(f\"Using scene: {scene_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build station from scenario and render a frame\n",
        "scenario = LoadScenario(filename=str(scene_path))\n",
        "station = MakeHardwareStation(scenario, meshcat=None)\n",
        "context = station.CreateDefaultContext()\n",
        "\n",
        "# Trigger a render so camera images are available\n",
        "station.ForcedPublish(context)\n",
        "\n",
        "# List available output ports to find cameras\n",
        "port_names = [station.get_output_port(i).get_name() for i in range(station.num_output_ports())]\n",
        "print(\"Outputs:\")\n",
        "for name in port_names:\n",
        "    print(\" -\", name)\n",
        "\n",
        "# Pick first rgb/depth ports that look like camera outputs\n",
        "rgb_port_name = next(n for n in port_names if \"rgb\" in n)\n",
        "depth_port_name = next(n for n in port_names if \"depth\" in n)\n",
        "print(f\"Using ports -> rgb: {rgb_port_name}, depth: {depth_port_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def drake_image_to_rgb(img: ImageRgba8U) -> np.ndarray:\n",
        "    \"\"\"Convert Drake ImageRgba8U to HxWx3 uint8 RGB array.\"\"\"\n",
        "    if img.size() == 0:\n",
        "        raise ValueError(\"Empty image\")\n",
        "    arr = np.array(img.data, copy=False).reshape(img.height(), img.width(), 4)\n",
        "    return arr[:, :, :3]\n",
        "\n",
        "# Extract images\n",
        "rgb_port = station.GetOutputPort(rgb_port_name)\n",
        "depth_port = station.GetOutputPort(depth_port_name)\n",
        "\n",
        "rgb_img = rgb_port.Eval(context)\n",
        "depth_img = depth_port.Eval(context)\n",
        "\n",
        "rgb = drake_image_to_rgb(rgb_img)\n",
        "# Depth is ImageDepth32F; reshape to HxW in meters\n",
        "if depth_img.size() > 0:\n",
        "    depth = np.array(depth_img.data).reshape(depth_img.height(), depth_img.width())\n",
        "else:\n",
        "    depth = None\n",
        "\n",
        "print(f\"RGB shape: {rgb.shape}, depth: {None if depth is None else depth.shape}\")\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(rgb)\n",
        "plt.title(f\"Scene: {scene_name}\")\n",
        "plt.axis('off');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple cube detection via color thresholding (tune for your cube color)\n",
        "# Example: orange foam brick\n",
        "hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)\n",
        "# Adjust these bounds to your cube color\n",
        "lower = np.array([5, 80, 80])   # hue,sat,val lower\n",
        "upper = np.array([25, 255, 255])\n",
        "mask = cv2.inRange(hsv, lower, upper)\n",
        "\n",
        "# Find largest contour\n",
        "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "if not contours:\n",
        "    raise RuntimeError(\"No cube-like contour found; adjust HSV bounds\")\n",
        "contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "main = contours[0]\n",
        "x, y, w, h = cv2.boundingRect(main)\n",
        "cx = int(x + w/2)\n",
        "cy = int(y + h/2)\n",
        "\n",
        "# Depth at centroid (if depth available)\n",
        "centroid_depth = float(depth[cy, cx]) if depth is not None else None\n",
        "\n",
        "# Draw result\n",
        "vis = rgb.copy()\n",
        "cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "cv2.circle(vis, (cx, cy), 4, (255, 0, 0), -1)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1); plt.imshow(rgb); plt.title('RGB'); plt.axis('off')\n",
        "plt.subplot(1,2,2); plt.imshow(vis); plt.title(f'Detected cube (depth={centroid_depth:.3f} m)' if centroid_depth else 'Detected cube'); plt.axis('off')\n",
        "plt.tight_layout();\n",
        "\n",
        "print(f\"Bounding box: x={x}, y={y}, w={w}, h={h}; depth={centroid_depth}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- Adjust HSV bounds (`lower`, `upper`) to your cube color if detection fails.\n",
        "- Depth sampling uses the centroid; for robustness, consider median depth over the mask region.\n",
        "- If port names differ, tweak the heuristics in the port selection cell (look for names containing `rgb` / `depth`).\n",
        "- To try another scene, set `scene_name` in the selection cell.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
